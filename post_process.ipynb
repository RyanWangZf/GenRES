{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def post_process(model_name, extract_func):\n",
    "    # Directory where your files are stored\n",
    "    directory = './results/'\n",
    "\n",
    "    # Pattern to match the files of interest\n",
    "    pattern = directory + f'*{model_name}*.json'\n",
    "\n",
    "    # Process each file\n",
    "    for file_path in glob.glob(pattern):\n",
    "        print(f\"Processing {file_path}...\")\n",
    "        \n",
    "        # Read the file\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Extract triples\n",
    "        text_triples = extract_func(data)\n",
    "        \n",
    "        # Define new file name for processed results\n",
    "        base_name = os.path.basename(file_path)\n",
    "        new_file_name = base_name.replace('results', 'processed_results')\n",
    "        new_file_path = os.path.join('./processed_results/', new_file_name)\n",
    "        \n",
    "        # Write the processed data to a new file\n",
    "        with open(new_file_path, 'w') as f:\n",
    "            json.dump(text_triples, f, indent=6)\n",
    "        \n",
    "        print(f\"Processed data saved to {new_file_path}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT Family: gpt-3.5-turbo-instruct & gpt-4 & text-davinci-003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_triples_gpt(data):\n",
    "    text_triples = defaultdict(list)\n",
    "    for text, triples_str in tqdm(data.items()):\n",
    "        # Use regex to find all JSON array-like structures\n",
    "        matches = re.findall(r'\\[\\[.*?\\]\\]', triples_str, re.DOTALL)\n",
    "        triple_list = []\n",
    "        for match in matches:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triples_raw = json.loads(match)\n",
    "                for triple in triples_raw:\n",
    "                    if len(triple) == 3:\n",
    "                        triple_list.append(triple)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                continue\n",
    "        text_triples[text] = triple_list\n",
    "    return text_triples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./results/nyt10m_rand_500_gpt-3.5-turbo-instruct_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 141403.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_gpt-3.5-turbo-instruct_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_gpt-3.5-turbo-instruct_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 56860.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_gpt-3.5-turbo-instruct_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_gpt-3.5-turbo-instruct_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 62359.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_gpt-3.5-turbo-instruct_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_gpt-4_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 165638.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_gpt-4_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_gpt-4_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 57796.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_gpt-4_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_gpt-4_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 59153.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_gpt-4_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_text-davinci-003_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 167731.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_text-davinci-003_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_text-davinci-003_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 65048.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_text-davinci-003_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_text-davinci-003_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 72129.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_text-davinci-003_1.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "post_process('gpt-3.5', extract_triples_gpt)\n",
    "post_process('gpt-4', extract_triples_gpt)\n",
    "post_process('davinci', extract_triples_gpt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLAMA Family: Vicuna-7B, Vicuna-33B, LLAMA-2-7B, LLAMA-2-70B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triples_vicuna(data):\n",
    "    text_triples = defaultdict(list)\n",
    "    for text, triples_str in tqdm(data.items()):\n",
    "        triples_str = triples_str.split(\"ASSISTANT:\")[1]\n",
    "        matches = re.findall(r'\\[\\[.*?\\]\\]', triples_str, re.DOTALL)\n",
    "        triple_list = []\n",
    "        for match in matches:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triples_raw = json.loads(match)\n",
    "                for triple in triples_raw:\n",
    "                    if len(triple) == 3:\n",
    "                        triple_list.append(triple)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                continue\n",
    "        text_triples[text] = triple_list\n",
    "    return text_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./results/nyt10m_rand_500_vicuna-1.3-33b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 117897.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_vicuna-1.3-33b_1.json\n",
      "\n",
      "Processing ./results/tacred_rand_800_vicuna-1.3-33b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 132448.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_vicuna-1.3-33b_1.json\n",
      "\n",
      "Processing ./results/wiki20m_rand_500_vicuna-1.3-33b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 142877.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki20m_rand_500_vicuna-1.3-33b_1.json\n",
      "\n",
      "Processing ./results/wiki80_rand_800_vicuna-1.3-33b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 163345.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki80_rand_800_vicuna-1.3-33b_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_vicuna-1.3-33b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 63062.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_vicuna-1.3-33b_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_vicuna-1.5-7b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 63315.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_vicuna-1.5-7b_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_vicuna-1.3-33b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 53301.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_vicuna-1.3-33b_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_vicuna-1.5-7b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 59935.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_vicuna-1.5-7b_1.json\n",
      "\n",
      "Processing ./results/wiki20m_rand_500_vicuna-1.5-7b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15307.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki20m_rand_500_vicuna-1.5-7b_1.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "post_process('vicuna', extract_triples_vicuna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triples_llama(data):\n",
    "    text_triples = defaultdict(list)\n",
    "    for text, triples_str in tqdm(data.items()):\n",
    "        triples_str = triples_str.split(\"[/INST]\")[1]\n",
    "        matches = re.findall(r'\\[.*?\\]', triples_str, re.DOTALL)\n",
    "        triple_list = []\n",
    "        for match in matches:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triple = json.loads(match)\n",
    "                if len(triple) == 3:\n",
    "                    triple_list.append(triple)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                continue\n",
    "        text_triples[text] = triple_list\n",
    "    return text_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_process('llama', extract_triples_llama)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triples_mistral(data):\n",
    "    text_triples = defaultdict(list)\n",
    "    for text, triples_str in tqdm(data.items()):\n",
    "        triples_str = triples_str.split(\"[/INST]\")[1]\n",
    "        matches = re.findall(r'\\[.*?\\]', triples_str, re.DOTALL)\n",
    "        triple_list = []\n",
    "        for match in matches:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triple = json.loads(match)\n",
    "                if len(triple) == 3:\n",
    "                    triple_list.append(triple)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                continue\n",
    "        text_triples[text] = triple_list\n",
    "    return text_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./results/nyt10m_rand_500_mistral_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 58903.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_mistral_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_mistral_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 20998.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_mistral_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_mistral_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 28478.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_mistral_1.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "post_process('mistral', extract_triples_mistral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triples_claude(data):\n",
    "    text_triples = defaultdict(list)\n",
    "    for text, triples_str in tqdm(data.items()):\n",
    "        triples_str = triples_str.split(\"[/INST]\")[1]\n",
    "        matches = re.findall(r'\\[.*?\\]', triples_str, re.DOTALL)\n",
    "        triple_list = []\n",
    "        for match in matches:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triple = json.loads(match)\n",
    "                if len(triple) == 3:\n",
    "                    triple_list.append(triple)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                continue\n",
    "        text_triples[text] = triple_list\n",
    "    return text_triples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('textgen')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72e4df05eb8a5f0bdb80d33a9292878c0e2ee2d3f5bd7213be092f7893c82c13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

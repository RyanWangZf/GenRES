{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def post_process(model_name, extract_func):\n",
    "    # Directory where your files are stored\n",
    "    directory = './results/'\n",
    "\n",
    "    # Pattern to match the files of interest\n",
    "    pattern = directory + f'*{model_name}*.json'\n",
    "\n",
    "    # Process each file\n",
    "    for file_path in glob.glob(pattern):\n",
    "        print(f\"Processing {file_path}...\")\n",
    "        \n",
    "        # Read the file\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Extract triples\n",
    "        text_triples = extract_func(data)\n",
    "        \n",
    "        # Define new file name for processed results\n",
    "        base_name = os.path.basename(file_path)\n",
    "        new_file_name = base_name.replace('results', 'processed_results')\n",
    "        new_file_path = os.path.join('./processed_results/', new_file_name)\n",
    "        \n",
    "        # Write the processed data to a new file\n",
    "        with open(new_file_path, 'w') as f:\n",
    "            json.dump(text_triples, f, indent=6)\n",
    "        \n",
    "        print(f\"Processed data saved to {new_file_path}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT Family: gpt-3.5-turbo-instruct & gpt-4 & text-davinci-003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_triples_gpt(data):\n",
    "    text_triples = defaultdict(list)\n",
    "    for text, triples_str in tqdm(data.items()):\n",
    "        # Use regex to find all JSON array-like structures\n",
    "        repeat_map = {}\n",
    "        matches_1 = re.findall(r'\\[.*?\\]', triples_str, re.DOTALL)\n",
    "        matches_2 = re.findall(r'\\[\\[.*?\\]\\]', triples_str, re.DOTALL)\n",
    "        triple_list = []\n",
    "        for match in matches_1:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triple = json.loads(match)\n",
    "                if len(triple) == 3:\n",
    "                    triple_list.append(triple)\n",
    "                if str(triple) not in repeat_map:\n",
    "                    repeat_map[str(triple)] = 1\n",
    "                else:\n",
    "                    repeat_map[str(triple)] += 1\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                    continue\n",
    "        text_triples[text] = triple_list\n",
    "        \n",
    "        \n",
    "        for match in matches_2:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triples = json.loads(match)\n",
    "                for triple in triples:\n",
    "                    if str(triple) not in repeat_map:\n",
    "                        repeat_map[str(triple)] = 1\n",
    "                    elif repeat_map[str(triple)] == 1:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                    if len(triple) == 3:\n",
    "                        triple_list.append(triple)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                continue\n",
    "        text_triples[text] = triple_list\n",
    "    return text_triples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./results/nyt10m_rand_500_gpt-3.5-turbo-instruct_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 23745.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_gpt-3.5-turbo-instruct_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_gpt-3.5-turbo-1106_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 47843.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_gpt-3.5-turbo-1106_1.json\n",
      "\n",
      "Processing ./results/wiki80_rand_800_gpt-3.5-turbo-1106_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 63131.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki80_rand_800_gpt-3.5-turbo-1106_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_gpt-3.5-turbo-instruct_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 10102.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_gpt-3.5-turbo-instruct_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_gpt-3.5-turbo-instruct_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 10872.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_gpt-3.5-turbo-instruct_1.json\n",
      "\n",
      "Processing ./results/tacred_rand_800_gpt-3.5-turbo-1106_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 49895.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_gpt-3.5-turbo-1106_1.json\n",
      "\n",
      "Processing ./results/tacred_rand_800_gpt-3.5-turbo-instruct_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 34793.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_gpt-3.5-turbo-instruct_1.json\n",
      "\n",
      "Processing ./results/wiki80_rand_800_gpt-3.5-turbo-instruct_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 39088.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki80_rand_800_gpt-3.5-turbo-instruct_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_gpt-3.5-turbo-1106_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 11752.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_gpt-3.5-turbo-1106_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_gpt-3.5-turbo-1106_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 14547.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_gpt-3.5-turbo-1106_1.json\n",
      "\n",
      "Processing ./results/wiki20m_rand_500_gpt-3.5-turbo-instruct_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 35777.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki20m_rand_500_gpt-3.5-turbo-instruct_1.json\n",
      "\n",
      "Processing ./results/wiki20m_rand_500_gpt-3.5-turbo-1106_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 61168.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki20m_rand_500_gpt-3.5-turbo-1106_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_gpt-4_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 34243.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_gpt-4_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_gpt-4-1106-preview_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 8421.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_gpt-4-1106-preview_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_gpt-4_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 9988.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_gpt-4_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_gpt-4_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 12234.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_gpt-4_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_gpt-4-1106-preview_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 32945.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_gpt-4-1106-preview_1.json\n",
      "\n",
      "Processing ./results/wiki80_rand_800_gpt-4_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 43598.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki80_rand_800_gpt-4_1.json\n",
      "\n",
      "Processing ./results/tacred_rand_800_gpt-4_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 40245.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_gpt-4_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_gpt-4-1106-preview_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 9893.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_gpt-4-1106-preview_1.json\n",
      "\n",
      "Processing ./results/wiki20m_rand_500_gpt-4-1106-preview_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 41403.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki20m_rand_500_gpt-4-1106-preview_1.json\n",
      "\n",
      "Processing ./results/wiki20m_rand_500_gpt-4_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 45159.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki20m_rand_500_gpt-4_1.json\n",
      "\n",
      "Processing ./results/tacred_rand_800_gpt-4-1106-preview_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 38980.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_gpt-4-1106-preview_1.json\n",
      "\n",
      "Processing ./results/wiki80_rand_800_gpt-4-1106-preview_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 42737.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki80_rand_800_gpt-4-1106-preview_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_text-davinci-003_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 36453.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_text-davinci-003_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_text-davinci-003_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 11904.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_text-davinci-003_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_text-davinci-003_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 14317.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_text-davinci-003_1.json\n",
      "\n",
      "Processing ./results/tacred_rand_800_text-davinci-003_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 13071.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_text-davinci-003_1.json\n",
      "\n",
      "Processing ./results/wiki80_rand_800_text-davinci-003_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 42293.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki80_rand_800_text-davinci-003_1.json\n",
      "\n",
      "Processing ./results/wiki20m_rand_500_text-davinci-003_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 44194.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki20m_rand_500_text-davinci-003_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_gpt-4-1106-preview_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 8468.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_gpt-4-1106-preview_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_gpt-4-1106-preview_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 33417.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_gpt-4-1106-preview_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_gpt-4-1106-preview_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 9406.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_gpt-4-1106-preview_1.json\n",
      "\n",
      "Processing ./results/wiki20m_rand_500_gpt-4-1106-preview_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 41031.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki20m_rand_500_gpt-4-1106-preview_1.json\n",
      "\n",
      "Processing ./results/tacred_rand_800_gpt-4-1106-preview_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 38693.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_gpt-4-1106-preview_1.json\n",
      "\n",
      "Processing ./results/wiki80_rand_800_gpt-4-1106-preview_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 41320.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki80_rand_800_gpt-4-1106-preview_1.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "post_process('gpt-3.5', extract_triples_gpt)\n",
    "post_process('gpt-4', extract_triples_gpt)\n",
    "post_process('davinci', extract_triples_gpt)\n",
    "post_process('gpt-4-1106', extract_triples_gpt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLAMA Family: Vicuna-7B, Vicuna-33B, LLAMA-2-7B, LLAMA-2-70B, Wizard-70B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triples_vicuna(data):\n",
    "    text_triples = defaultdict(list)\n",
    "    for text, triples_str in tqdm(data.items()):\n",
    "        triples_str = triples_str.split(\"\\nASSISTANT:\")[1]\n",
    "        repeat_map = {}\n",
    "        matches_1 = re.findall(r'\\[.*?\\]', triples_str, re.DOTALL)\n",
    "        matches_2 = re.findall(r'\\[\\[.*?\\]\\]', triples_str, re.DOTALL)\n",
    "        triple_list = []\n",
    "        for match in matches_1:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triple = json.loads(match)\n",
    "                if len(triple) == 3:\n",
    "                    triple_list.append(triple)\n",
    "                if str(triple) not in repeat_map:\n",
    "                    repeat_map[str(triple)] = 1\n",
    "                else:\n",
    "                    repeat_map[str(triple)] += 1\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                    continue\n",
    "        text_triples[text] = triple_list\n",
    "        \n",
    "        \n",
    "        for match in matches_2:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triples = json.loads(match)\n",
    "                for triple in triples:\n",
    "                    if str(triple) not in repeat_map:\n",
    "                        repeat_map[str(triple)] = 1\n",
    "                    elif repeat_map[str(triple)] == 1:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                    if len(triple) == 3:\n",
    "                        triple_list.append(triple)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                continue\n",
    "        text_triples[text] = triple_list\n",
    "    return text_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./results/tacred_rand_800_vicuna-1.5-7b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 50593.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_vicuna-1.5-7b_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_vicuna-1.3-33b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 31998.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_vicuna-1.3-33b_1.json\n",
      "\n",
      "Processing ./results/tacred_rand_800_vicuna-1.3-33b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 800/800 [00:00<00:00, 37571.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_vicuna-1.3-33b_1.json\n",
      "\n",
      "Processing ./results/wiki80_rand_800_vicuna-1.3-33b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 41290.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki80_rand_800_vicuna-1.3-33b_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_vicuna-1.3-33b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 13513.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_vicuna-1.3-33b_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_vicuna-1.5-7b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 13366.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_vicuna-1.5-7b_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_vicuna-1.3-33b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 11669.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_vicuna-1.3-33b_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_vicuna-1.5-7b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:00<00:00, 12893.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_vicuna-1.5-7b_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_vicuna-1.5-7b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 38623.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_vicuna-1.5-7b_1.json\n",
      "\n",
      "Processing ./results/wiki20m_rand_500_vicuna-1.5-7b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 44702.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki20m_rand_500_vicuna-1.5-7b_1.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "post_process('vicuna', extract_triples_vicuna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triples_llama(data):\n",
    "    text_triples = defaultdict(list)\n",
    "    for text, triples_str in tqdm(data.items()):\n",
    "        triples_str = triples_str.split(\"[/INST]\")[1]\n",
    "        repeat_map = {}\n",
    "        matches_1 = re.findall(r'\\[.*?\\]', triples_str, re.DOTALL)\n",
    "        matches_2 = re.findall(r'\\[\\[.*?\\]\\]', triples_str, re.DOTALL)\n",
    "        triple_list = []\n",
    "        for match in matches_1:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triple = json.loads(match)\n",
    "                if len(triple) == 3:\n",
    "                    triple_list.append(triple)\n",
    "                if str(triple) not in repeat_map:\n",
    "                    repeat_map[str(triple)] = 1\n",
    "                else:\n",
    "                    repeat_map[str(triple)] += 1\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                    continue\n",
    "        text_triples[text] = triple_list\n",
    "        \n",
    "        \n",
    "        for match in matches_2:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triples = json.loads(match)\n",
    "                for triple in triples:\n",
    "                    if str(triple) not in repeat_map:\n",
    "                        repeat_map[str(triple)] = 1\n",
    "                    elif repeat_map[str(triple)] == 1:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                    if len(triple) == 3:\n",
    "                        triple_list.append(triple)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                continue\n",
    "        text_triples[text] = triple_list\n",
    "    return text_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./results/tacred_rand_800_llama-2-70b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 38290.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_llama-2-70b_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_llama-2-70b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 11305.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_llama-2-70b_1.json\n",
      "\n",
      "Processing ./results/wiki20m_rand_500_llama-2-70b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 37058.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki20m_rand_500_llama-2-70b_1.json\n",
      "\n",
      "Processing ./results/wiki80_rand_800_llama-2-70b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 39838.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki80_rand_800_llama-2-70b_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_llama-2-7b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 44424.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_llama-2-7b_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_llama-2-70b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:00<00:00, 13362.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_llama-2-70b_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_llama-2-7b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 18327.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_llama-2-7b_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_llama-2-70b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 31711.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_llama-2-70b_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_llama-2-70b_2.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:00<00:00, 13997.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_llama-2-70b_2.json\n",
      "\n",
      "Processing ./results/tacred_rand_800_llama-2-7b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 38155.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_llama-2-7b_1.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "post_process('llama', extract_triples_llama)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wizard-70B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./results/docred_rand_200_wizardlm-70b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 28885.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_wizardlm-70b_1.json\n",
      "\n",
      "Processing ./results/wiki80_rand_800_wizardlm-70b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 49785.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki80_rand_800_wizardlm-70b_1.json\n",
      "\n",
      "Processing ./results/tacred_rand_800_wizardlm-70b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 48327.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_wizardlm-70b_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_wizardlm-70b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 40917.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_wizardlm-70b_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_wizardlm-70b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 20063.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_wizardlm-70b_1.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "post_process('wizard', extract_triples_vicuna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triples_mistral(data):\n",
    "    text_triples = defaultdict(list)\n",
    "    for text, triples_str in tqdm(data.items()):\n",
    "        triples_str = triples_str.split(\"[/INST]\")[1]\n",
    "        repeat_map = {}\n",
    "        matches_1 = re.findall(r'\\[.*?\\]', triples_str, re.DOTALL)\n",
    "        matches_2 = re.findall(r'\\[\\[.*?\\]\\]', triples_str, re.DOTALL)\n",
    "        triple_list = []\n",
    "        for match in matches_1:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triple = json.loads(match)\n",
    "                if len(triple) == 3:\n",
    "                    triple_list.append(triple)\n",
    "                if str(triple) not in repeat_map:\n",
    "                    repeat_map[str(triple)] = 1\n",
    "                else:\n",
    "                    repeat_map[str(triple)] += 1\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                    continue\n",
    "        text_triples[text] = triple_list\n",
    "        \n",
    "        \n",
    "        for match in matches_2:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triples = json.loads(match)\n",
    "                for triple in triples:\n",
    "                    if str(triple) not in repeat_map:\n",
    "                        repeat_map[str(triple)] = 1\n",
    "                    elif repeat_map[str(triple)] == 1:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                    if len(triple) == 3:\n",
    "                        triple_list.append(triple)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                continue\n",
    "        text_triples[text] = triple_list\n",
    "    return text_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./results/nyt10m_rand_500_mistral_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 35384.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_mistral_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_mistral_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 11112.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_mistral_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_mistral_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 13238.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_mistral_1.json\n",
      "\n",
      "Processing ./results/tacred_rand_800_mistral_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 10530.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_mistral_1.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "post_process('mistral', extract_triples_mistral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GALACTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triples_galactica(data):\n",
    "    text_triples = defaultdict(list)\n",
    "    for text, triples_str in tqdm(data.items()):\n",
    "        repeat_map = {}\n",
    "        matches_1 = re.findall(r'\\[.*?\\]', triples_str, re.DOTALL)\n",
    "        matches_2 = re.findall(r'\\[\\[.*?\\]\\]', triples_str, re.DOTALL)\n",
    "        triple_list = []\n",
    "        for match in matches_1:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triple = json.loads(match)\n",
    "                if len(triple) == 3:\n",
    "                    triple_list.append(triple)\n",
    "                if str(triple) not in repeat_map:\n",
    "                    repeat_map[str(triple)] = 1\n",
    "                else:\n",
    "                    repeat_map[str(triple)] += 1\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                    continue\n",
    "        text_triples[text] = triple_list\n",
    "        \n",
    "        \n",
    "        for match in matches_2:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triples = json.loads(match)\n",
    "                for triple in triples:\n",
    "                    if str(triple) not in repeat_map:\n",
    "                        repeat_map[str(triple)] = 1\n",
    "                    elif repeat_map[str(triple)] == 1:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                    if len(triple) == 3:\n",
    "                        triple_list.append(triple)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                continue\n",
    "        text_triples[text] = triple_list\n",
    "    return text_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./results/wiki80_rand_800_galactica-30b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 35486.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki80_rand_800_galactica-30b_1.json\n",
      "\n",
      "Processing ./results/tacred_rand_800_galactica-30b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 25586.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_galactica-30b_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_galactica-30b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 598758.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_galactica-30b_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_galactica-30b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 296941.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_galactica-30b_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_galactica-30b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 24861.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_galactica-30b_1.json\n",
      "\n",
      "Processing ./results/wiki20m_rand_500_galactica-30b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 31458.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki20m_rand_500_galactica-30b_1.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "post_process('galactica', extract_triples_galactica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zephyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triples_zephyr(data):\n",
    "    text_triples = defaultdict(list)\n",
    "    for text, triples_str in tqdm(data.items()):\n",
    "        triples_str = triples_str.split(\"\\n<|assistant|>\\n\")[1]\n",
    "        repeat_map = {}\n",
    "        matches_1 = re.findall(r'\\[.*?\\]', triples_str, re.DOTALL)\n",
    "        matches_2 = re.findall(r'\\[\\[.*?\\]\\]', triples_str, re.DOTALL)\n",
    "        triple_list = []\n",
    "        for match in matches_1:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triple = json.loads(match)\n",
    "                if len(triple) == 3:\n",
    "                    triple_list.append(triple)\n",
    "                if str(triple) not in repeat_map:\n",
    "                    repeat_map[str(triple)] = 1\n",
    "                else:\n",
    "                    repeat_map[str(triple)] += 1\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                    continue\n",
    "        text_triples[text] = triple_list\n",
    "        \n",
    "        \n",
    "        for match in matches_2:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triples = json.loads(match)\n",
    "                for triple in triples:\n",
    "                    if str(triple) not in repeat_map:\n",
    "                        repeat_map[str(triple)] = 1\n",
    "                    elif repeat_map[str(triple)] == 1:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                    if len(triple) == 3:\n",
    "                        triple_list.append(triple)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                continue\n",
    "        text_triples[text] = triple_list\n",
    "    return text_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./results/tacred_rand_800_zephyr-7b-beta_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 30405.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_zephyr-7b-beta_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_zephyr-7b-beta_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 9367.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_zephyr-7b-beta_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_zephyr-7b-beta_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 6524.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_zephyr-7b-beta_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_zephyr-7b-beta_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 21003.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_zephyr-7b-beta_1.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "post_process('zephyr', extract_triples_zephyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### openchat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triples_openchat(data):\n",
    "    text_triples = defaultdict(list)\n",
    "    for text, triples_str in tqdm(data.items()):\n",
    "        triples_str = triples_str.split(\"GPT4 Correct Assistant:\")[1]\n",
    "        repeat_map = {}\n",
    "        matches_1 = re.findall(r'\\[.*?\\]', triples_str, re.DOTALL)\n",
    "        matches_2 = re.findall(r'\\[\\[.*?\\]\\]', triples_str, re.DOTALL)\n",
    "        triple_list = []\n",
    "        for match in matches_1:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triple = json.loads(match)\n",
    "                if len(triple) == 3:\n",
    "                    triple_list.append(triple)\n",
    "                if str(triple) not in repeat_map:\n",
    "                    repeat_map[str(triple)] = 1\n",
    "                else:\n",
    "                    repeat_map[str(triple)] += 1\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                    continue\n",
    "        text_triples[text] = triple_list\n",
    "        \n",
    "        \n",
    "        for match in matches_2:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triples = json.loads(match)\n",
    "                for triple in triples:\n",
    "                    if str(triple) not in repeat_map:\n",
    "                        repeat_map[str(triple)] = 1\n",
    "                    elif repeat_map[str(triple)] == 1:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                    if len(triple) == 3:\n",
    "                        triple_list.append(triple)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                continue\n",
    "        text_triples[text] = triple_list\n",
    "    return text_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./results/wiki80_rand_800_openchat_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 42052.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki80_rand_800_openchat_1.json\n",
      "\n",
      "Processing ./results/tacred_rand_800_openchat_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 39000.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_openchat_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_openchat_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 500/500 [00:00<00:00, 33667.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_openchat_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_openchat_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 15638.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_openchat_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_openchat_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 11490.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_openchat_1.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "post_process('openchat', extract_triples_openchat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('textgen')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72e4df05eb8a5f0bdb80d33a9292878c0e2ee2d3f5bd7213be092f7893c82c13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

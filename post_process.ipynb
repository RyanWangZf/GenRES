{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def post_process(model_name, extract_func):\n",
    "    # Directory where your files are stored\n",
    "    directory = './results/'\n",
    "\n",
    "    # Pattern to match the files of interest\n",
    "    pattern = directory + f'*{model_name}*.json'\n",
    "\n",
    "    # Process each file\n",
    "    for file_path in glob.glob(pattern):\n",
    "        print(f\"Processing {file_path}...\")\n",
    "        \n",
    "        # Read the file\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Extract triples\n",
    "        text_triples = extract_func(data)\n",
    "        \n",
    "        # Define new file name for processed results\n",
    "        base_name = os.path.basename(file_path)\n",
    "        new_file_name = base_name.replace('results', 'processed_results')\n",
    "        new_file_path = os.path.join('./processed_results/', new_file_name)\n",
    "        \n",
    "        # Write the processed data to a new file\n",
    "        with open(new_file_path, 'w') as f:\n",
    "            json.dump(text_triples, f, indent=6)\n",
    "        \n",
    "        print(f\"Processed data saved to {new_file_path}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT Family: gpt-3.5-turbo-instruct & gpt-4 & text-davinci-003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_triples_gpt(data):\n",
    "    text_triples = defaultdict(list)\n",
    "    for text, triples_str in tqdm(data.items()):\n",
    "        # Use regex to find all JSON array-like structures\n",
    "        repeat_map = {}\n",
    "        matches_1 = re.findall(r'\\[.*?\\]', triples_str, re.DOTALL)\n",
    "        matches_2 = re.findall(r'\\[\\[.*?\\]\\]', triples_str, re.DOTALL)\n",
    "        triple_list = []\n",
    "        for match in matches_1:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triple = json.loads(match)\n",
    "                if len(triple) == 3:\n",
    "                    triple_list.append(triple)\n",
    "                if str(triple) not in repeat_map:\n",
    "                    repeat_map[str(triple)] = 1\n",
    "                else:\n",
    "                    repeat_map[str(triple)] += 1\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                    continue\n",
    "        text_triples[text] = triple_list\n",
    "        \n",
    "        \n",
    "        for match in matches_2:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triples = json.loads(match)\n",
    "                for triple in triples:\n",
    "                    if str(triple) not in repeat_map:\n",
    "                        repeat_map[str(triple)] = 1\n",
    "                    elif repeat_map[str(triple)] == 1:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                    if len(triple) == 3:\n",
    "                        triple_list.append(triple)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                continue\n",
    "        text_triples[text] = triple_list\n",
    "    return text_triples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./results/nyt10m_rand_500_gpt-3.5-turbo-instruct_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 28735.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_gpt-3.5-turbo-instruct_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_gpt-3.5-turbo-1106_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 45266.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_gpt-3.5-turbo-1106_1.json\n",
      "\n",
      "Processing ./results/wiki80_rand_800_gpt-3.5-turbo-1106_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 57965.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki80_rand_800_gpt-3.5-turbo-1106_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_gpt-3.5-turbo-instruct_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 9837.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_gpt-3.5-turbo-instruct_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_gpt-3.5-turbo-instruct_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 10465.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_gpt-3.5-turbo-instruct_1.json\n",
      "\n",
      "Processing ./results/tacred_rand_800_gpt-3.5-turbo-1106_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 50881.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_gpt-3.5-turbo-1106_1.json\n",
      "\n",
      "Processing ./results/tacred_rand_800_gpt-3.5-turbo-instruct_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 33746.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_gpt-3.5-turbo-instruct_1.json\n",
      "\n",
      "Processing ./results/wiki80_rand_800_gpt-3.5-turbo-instruct_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 37295.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki80_rand_800_gpt-3.5-turbo-instruct_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_gpt-3.5-turbo-1106_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 11811.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_gpt-3.5-turbo-1106_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_gpt-3.5-turbo-1106_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 14223.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_gpt-3.5-turbo-1106_1.json\n",
      "\n",
      "Processing ./results/wiki20m_rand_500_gpt-3.5-turbo-instruct_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 35749.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki20m_rand_500_gpt-3.5-turbo-instruct_1.json\n",
      "\n",
      "Processing ./results/wiki20m_rand_500_gpt-3.5-turbo-1106_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 60697.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki20m_rand_500_gpt-3.5-turbo-1106_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_gpt-4_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 34472.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_gpt-4_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_gpt-4-1106-preview_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 9003.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_gpt-4-1106-preview_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_gpt-4_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 9881.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_gpt-4_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_gpt-4_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 12065.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_gpt-4_1.json\n",
      "\n",
      "Processing ./results/wiki80_rand_800_gpt-4_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 41440.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki80_rand_800_gpt-4_1.json\n",
      "\n",
      "Processing ./results/tacred_rand_800_gpt-4_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 39729.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_gpt-4_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_gpt-4-1106-preview_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 9576.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_gpt-4-1106-preview_1.json\n",
      "\n",
      "Processing ./results/wiki20m_rand_500_gpt-4_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 42394.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki20m_rand_500_gpt-4_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_text-davinci-003_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 35794.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_text-davinci-003_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_text-davinci-003_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 11328.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_text-davinci-003_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_text-davinci-003_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:00<00:00, 13513.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_text-davinci-003_1.json\n",
      "\n",
      "Processing ./results/tacred_rand_800_text-davinci-003_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 39189.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_text-davinci-003_1.json\n",
      "\n",
      "Processing ./results/wiki80_rand_800_text-davinci-003_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 39826.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki80_rand_800_text-davinci-003_1.json\n",
      "\n",
      "Processing ./results/wiki20m_rand_500_text-davinci-003_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 42808.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki20m_rand_500_text-davinci-003_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_gpt-4-1106-preview_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 9106.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_gpt-4-1106-preview_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_gpt-4-1106-preview_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 8313.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_gpt-4-1106-preview_1.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "post_process('gpt-3.5', extract_triples_gpt)\n",
    "post_process('gpt-4', extract_triples_gpt)\n",
    "post_process('davinci', extract_triples_gpt)\n",
    "post_process('gpt-4-1106', extract_triples_gpt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLAMA Family: Vicuna-7B, Vicuna-33B, LLAMA-2-7B, LLAMA-2-70B, Wizard-70B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triples_vicuna(data):\n",
    "    text_triples = defaultdict(list)\n",
    "    for text, triples_str in tqdm(data.items()):\n",
    "        triples_str = triples_str.split(\"\\nASSISTANT:\")[1]\n",
    "        repeat_map = {}\n",
    "        matches_1 = re.findall(r'\\[.*?\\]', triples_str, re.DOTALL)\n",
    "        matches_2 = re.findall(r'\\[\\[.*?\\]\\]', triples_str, re.DOTALL)\n",
    "        triple_list = []\n",
    "        for match in matches_1:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triple = json.loads(match)\n",
    "                if len(triple) == 3:\n",
    "                    triple_list.append(triple)\n",
    "                if str(triple) not in repeat_map:\n",
    "                    repeat_map[str(triple)] = 1\n",
    "                else:\n",
    "                    repeat_map[str(triple)] += 1\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                    continue\n",
    "        text_triples[text] = triple_list\n",
    "        \n",
    "        \n",
    "        for match in matches_2:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triples = json.loads(match)\n",
    "                for triple in triples:\n",
    "                    if str(triple) not in repeat_map:\n",
    "                        repeat_map[str(triple)] = 1\n",
    "                    elif repeat_map[str(triple)] == 1:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                    if len(triple) == 3:\n",
    "                        triple_list.append(triple)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                continue\n",
    "        text_triples[text] = triple_list\n",
    "    return text_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./results/tacred_rand_800_vicuna-1.5-7b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 47720.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_vicuna-1.5-7b_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_vicuna-1.3-33b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 31264.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_vicuna-1.3-33b_1.json\n",
      "\n",
      "Processing ./results/tacred_rand_800_vicuna-1.3-33b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 10645.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_vicuna-1.3-33b_1.json\n",
      "\n",
      "Processing ./results/wiki80_rand_800_vicuna-1.3-33b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 39759.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki80_rand_800_vicuna-1.3-33b_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_vicuna-1.3-33b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 13559.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_vicuna-1.3-33b_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_vicuna-1.5-7b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 13282.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_vicuna-1.5-7b_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_vicuna-1.3-33b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 10857.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_vicuna-1.3-33b_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_vicuna-1.5-7b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 12510.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_vicuna-1.5-7b_1.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "post_process('vicuna', extract_triples_vicuna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triples_llama(data):\n",
    "    text_triples = defaultdict(list)\n",
    "    for text, triples_str in tqdm(data.items()):\n",
    "        triples_str = triples_str.split(\"[/INST]\")[1]\n",
    "        repeat_map = {}\n",
    "        matches_1 = re.findall(r'\\[.*?\\]', triples_str, re.DOTALL)\n",
    "        matches_2 = re.findall(r'\\[\\[.*?\\]\\]', triples_str, re.DOTALL)\n",
    "        triple_list = []\n",
    "        for match in matches_1:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triple = json.loads(match)\n",
    "                if len(triple) == 3:\n",
    "                    triple_list.append(triple)\n",
    "                if str(triple) not in repeat_map:\n",
    "                    repeat_map[str(triple)] = 1\n",
    "                else:\n",
    "                    repeat_map[str(triple)] += 1\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                    continue\n",
    "        text_triples[text] = triple_list\n",
    "        \n",
    "        \n",
    "        for match in matches_2:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triples = json.loads(match)\n",
    "                for triple in triples:\n",
    "                    if str(triple) not in repeat_map:\n",
    "                        repeat_map[str(triple)] = 1\n",
    "                    elif repeat_map[str(triple)] == 1:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                    if len(triple) == 3:\n",
    "                        triple_list.append(triple)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                continue\n",
    "        text_triples[text] = triple_list\n",
    "    return text_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./results/tacred_rand_800_llama-2-70b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 36763.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_llama-2-70b_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_llama-2-70b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 10226.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_llama-2-70b_1.json\n",
      "\n",
      "Processing ./results/wiki20m_rand_500_llama-2-70b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 36279.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki20m_rand_500_llama-2-70b_1.json\n",
      "\n",
      "Processing ./results/wiki80_rand_800_llama-2-70b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 38855.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki80_rand_800_llama-2-70b_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_llama-2-7b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 42799.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_llama-2-7b_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_llama-2-70b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:00<00:00, 13240.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_llama-2-70b_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_llama-2-7b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 17955.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_llama-2-7b_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_llama-2-70b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 30876.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_llama-2-70b_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_llama-2-70b_2.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 13599.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_llama-2-70b_2.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "post_process('llama', extract_triples_llama)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wizard-70B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./results/wiki80_rand_800_wizardlm-70b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 49321.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki80_rand_800_wizardlm-70b_1.json\n",
      "\n",
      "Processing ./results/tacred_rand_800_wizardlm-70b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 46159.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_wizardlm-70b_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_wizardlm-70b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 39360.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_wizardlm-70b_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_wizardlm-70b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 19759.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_wizardlm-70b_1.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "post_process('wizard', extract_triples_vicuna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triples_mistral(data):\n",
    "    text_triples = defaultdict(list)\n",
    "    for text, triples_str in tqdm(data.items()):\n",
    "        triples_str = triples_str.split(\"[/INST]\")[1]\n",
    "        repeat_map = {}\n",
    "        matches_1 = re.findall(r'\\[.*?\\]', triples_str, re.DOTALL)\n",
    "        matches_2 = re.findall(r'\\[\\[.*?\\]\\]', triples_str, re.DOTALL)\n",
    "        triple_list = []\n",
    "        for match in matches_1:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triple = json.loads(match)\n",
    "                if len(triple) == 3:\n",
    "                    triple_list.append(triple)\n",
    "                if str(triple) not in repeat_map:\n",
    "                    repeat_map[str(triple)] = 1\n",
    "                else:\n",
    "                    repeat_map[str(triple)] += 1\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                    continue\n",
    "        text_triples[text] = triple_list\n",
    "        \n",
    "        \n",
    "        for match in matches_2:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triples = json.loads(match)\n",
    "                for triple in triples:\n",
    "                    if str(triple) not in repeat_map:\n",
    "                        repeat_map[str(triple)] = 1\n",
    "                    elif repeat_map[str(triple)] == 1:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                    if len(triple) == 3:\n",
    "                        triple_list.append(triple)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                continue\n",
    "        text_triples[text] = triple_list\n",
    "    return text_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./results/nyt10m_rand_500_mistral_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 34155.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_mistral_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_mistral_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 10363.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_mistral_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_mistral_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 13202.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_mistral_1.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "post_process('mistral', extract_triples_mistral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GALACTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triples_galactica(data):\n",
    "    text_triples = defaultdict(list)\n",
    "    for text, triples_str in tqdm(data.items()):\n",
    "        repeat_map = {}\n",
    "        matches_1 = re.findall(r'\\[.*?\\]', triples_str, re.DOTALL)\n",
    "        matches_2 = re.findall(r'\\[\\[.*?\\]\\]', triples_str, re.DOTALL)\n",
    "        triple_list = []\n",
    "        for match in matches_1:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triple = json.loads(match)\n",
    "                if len(triple) == 3:\n",
    "                    triple_list.append(triple)\n",
    "                if str(triple) not in repeat_map:\n",
    "                    repeat_map[str(triple)] = 1\n",
    "                else:\n",
    "                    repeat_map[str(triple)] += 1\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                    continue\n",
    "        text_triples[text] = triple_list\n",
    "        \n",
    "        \n",
    "        for match in matches_2:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triples = json.loads(match)\n",
    "                for triple in triples:\n",
    "                    if str(triple) not in repeat_map:\n",
    "                        repeat_map[str(triple)] = 1\n",
    "                    elif repeat_map[str(triple)] == 1:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                    if len(triple) == 3:\n",
    "                        triple_list.append(triple)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                continue\n",
    "        text_triples[text] = triple_list\n",
    "    return text_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./results/wiki80_rand_800_galactica-30b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 33826.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki80_rand_800_galactica-30b_1.json\n",
      "\n",
      "Processing ./results/tacred_rand_800_galactica-30b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 23762.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_galactica-30b_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_galactica-30b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 492000.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_galactica-30b_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_galactica-30b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 262472.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_galactica-30b_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_galactica-30b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 23721.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_galactica-30b_1.json\n",
      "\n",
      "Processing ./results/wiki20m_rand_500_galactica-30b_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 29324.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki20m_rand_500_galactica-30b_1.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "post_process('galactica', extract_triples_galactica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zephyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triples_zephyr(data):\n",
    "    text_triples = defaultdict(list)\n",
    "    for text, triples_str in tqdm(data.items()):\n",
    "        triples_str = triples_str.split(\"\\n<|assistant|>\\n\")[1]\n",
    "        repeat_map = {}\n",
    "        matches_1 = re.findall(r'\\[.*?\\]', triples_str, re.DOTALL)\n",
    "        matches_2 = re.findall(r'\\[\\[.*?\\]\\]', triples_str, re.DOTALL)\n",
    "        triple_list = []\n",
    "        for match in matches_1:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triple = json.loads(match)\n",
    "                if len(triple) == 3:\n",
    "                    triple_list.append(triple)\n",
    "                if str(triple) not in repeat_map:\n",
    "                    repeat_map[str(triple)] = 1\n",
    "                else:\n",
    "                    repeat_map[str(triple)] += 1\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                    continue\n",
    "        text_triples[text] = triple_list\n",
    "        \n",
    "        \n",
    "        for match in matches_2:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triples = json.loads(match)\n",
    "                for triple in triples:\n",
    "                    if str(triple) not in repeat_map:\n",
    "                        repeat_map[str(triple)] = 1\n",
    "                    elif repeat_map[str(triple)] == 1:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                    if len(triple) == 3:\n",
    "                        triple_list.append(triple)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                continue\n",
    "        text_triples[text] = triple_list\n",
    "    return text_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./results/tacred_rand_800_zephyr-7b-beta_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 30193.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_zephyr-7b-beta_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_zephyr-7b-beta_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 9205.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_zephyr-7b-beta_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_zephyr-7b-beta_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 6433.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_zephyr-7b-beta_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_zephyr-7b-beta_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 20025.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_zephyr-7b-beta_1.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "post_process('zephyr', extract_triples_zephyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### openchat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triples_openchat(data):\n",
    "    text_triples = defaultdict(list)\n",
    "    for text, triples_str in tqdm(data.items()):\n",
    "        triples_str = triples_str.split(\"GPT4 Correct Assistant:\")[1]\n",
    "        repeat_map = {}\n",
    "        matches_1 = re.findall(r'\\[.*?\\]', triples_str, re.DOTALL)\n",
    "        matches_2 = re.findall(r'\\[\\[.*?\\]\\]', triples_str, re.DOTALL)\n",
    "        triple_list = []\n",
    "        for match in matches_1:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triple = json.loads(match)\n",
    "                if len(triple) == 3:\n",
    "                    triple_list.append(triple)\n",
    "                if str(triple) not in repeat_map:\n",
    "                    repeat_map[str(triple)] = 1\n",
    "                else:\n",
    "                    repeat_map[str(triple)] += 1\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                    continue\n",
    "        text_triples[text] = triple_list\n",
    "        \n",
    "        \n",
    "        for match in matches_2:\n",
    "            try:\n",
    "                # Attempt to parse each match as JSON\n",
    "                triples = json.loads(match)\n",
    "                for triple in triples:\n",
    "                    if str(triple) not in repeat_map:\n",
    "                        repeat_map[str(triple)] = 1\n",
    "                    elif repeat_map[str(triple)] == 1:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        repeat_map[str(triple)] += 1\n",
    "                    if len(triple) == 3:\n",
    "                        triple_list.append(triple)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle cases where the match is not valid JSON\n",
    "                continue\n",
    "        text_triples[text] = triple_list\n",
    "    return text_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./results/wiki80_rand_800_openchat_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 40949.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/wiki80_rand_800_openchat_1.json\n",
      "\n",
      "Processing ./results/tacred_rand_800_openchat_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 15053.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/tacred_rand_800_openchat_1.json\n",
      "\n",
      "Processing ./results/nyt10m_rand_500_openchat_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 31877.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/nyt10m_rand_500_openchat_1.json\n",
      "\n",
      "Processing ./results/cdr_rand_200_openchat_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 15654.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/cdr_rand_200_openchat_1.json\n",
      "\n",
      "Processing ./results/docred_rand_200_openchat_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 11250.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ./processed_results/docred_rand_200_openchat_1.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "post_process('openchat', extract_triples_openchat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('textgen')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72e4df05eb8a5f0bdb80d33a9292878c0e2ee2d3f5bd7213be092f7893c82c13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
